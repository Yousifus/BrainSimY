# LLM Bridge Prototype - Python Dependencies
# Phase 1 Implementation Requirements

# Core LLM Integration
openai>=1.0.0
anthropic>=0.3.0

# Natural Language Processing
nltk>=3.8
spacy>=3.6.0
transformers>=4.30.0

# Data Processing and Analysis
numpy>=1.24.0
pandas>=2.0.0
scipy>=1.10.0

# Text Similarity and Matching
difflib  # Built-in Python module
fuzzywuzzy>=0.18.0
python-levenshtein>=0.21.0

# Configuration and Environment
python-dotenv>=1.0.0
pyyaml>=6.0

# JSON and Data Serialization
jsonschema>=4.17.0

# Logging and Monitoring
structlog>=23.1.0

# Testing and Development
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0

# Type Hints and Code Quality
typing-extensions>=4.7.0
mypy>=1.5.0

# Date and Time Handling
python-dateutil>=2.8.0

# HTTP Requests (for API calls)
requests>=2.31.0
aiohttp>=3.8.0

# Async Support
asyncio  # Built-in Python module
asyncio-mqtt>=0.13.0  # If MQTT communication needed

# Mathematical Operations
sympy>=1.12  # For symbolic math if needed

# Regular Expressions (enhanced)
regex>=2023.6.3

# Memory and Performance Optimization
psutil>=5.9.0  # For system monitoring
memory-profiler>=0.60.0  # For memory profiling

# Caching
cachetools>=5.3.0

# Optional: Advanced NLP Models
# sentence-transformers>=2.2.0  # For advanced embeddings
# torch>=2.0.0  # If using PyTorch models

# Documentation Generation
sphinx>=7.0.0  # For generating documentation
sphinx-rtd-theme>=1.3.0

# Development Tools
black>=23.0.0  # Code formatting
isort>=5.12.0  # Import sorting
flake8>=6.0.0  # Linting

# Note: Some packages may require additional system dependencies
# For spaCy language models, run:
# python -m spacy download en_core_web_sm

# For NLTK data, run in Python:
# import nltk
# nltk.download('punkt')
# nltk.download('stopwords')
# nltk.download('wordnet')