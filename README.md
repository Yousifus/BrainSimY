# BrainSimY: Forging Embodied AI Experiences

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![.NET](https://img.shields.io/badge/.NET-8.0-blue.svg)](https://dotnet.microsoft.com/)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![WPF](https://img.shields.io/badge/UI-WPF-lightblue.svg)](https://docs.microsoft.com/en-us/dotnet/desktop/wpf/)
[![Future AI Society](https://img.shields.io/badge/Supported%20by-Future%20AI%20Society-purple.svg)](https://futureaisociety.org)

<div align="center">

**🧠 A Neuro-Symbolic Platform for True Understanding 🤖**

*Moving beyond pattern recognition to create systems with genuine understanding*

</div>

---

## 🎯 **Vision Statement**

BrainSimY is a research platform dedicated to a fundamental challenge in artificial intelligence: **moving beyond pattern recognition to create systems with genuine understanding**. This project extends the pioneering BrainSimIII, leveraging its powerful Universal Knowledge Store (UKS) to serve a revolutionary new purpose: providing a sophisticated "embodied experience" for Large Language Models (LLMs).

We're bridging the fluid, intuitive capabilities of neural networks with the rigorous, logical framework of a symbolic commonsense engine, creating a **new form of hybrid intelligence**.

---

## 🏗️ **Core Pillars**

### 🧭 **The Universal Knowledge Store (UKS): The Mind's Canvas**
- **Graph-based knowledge representation** with inheritance and exceptions (mimicking human cognition)
- **Temporal knowledge** with expiration and **probabilistic reasoning** with confidence scores
- **Conditional logic** and rule-based reasoning that handles nebulous/conflicting information
- **Multi-sensory integration** connecting sounds, words, and images

### ⚡ **The Hybrid C#/Python Architecture: A Bilingual Brain**
- **C# (.NET 8.0)** performance for knowledge operations with **Python 3.8+** flexibility for LLM integration
- Seamless communication via **Python.NET bridge**
- **Modular agent system** for easy extension and experimentation
- **Cross-platform support** (Windows, macOS, Linux)

### 🔄 **The LLM-UKS Bridge: The Neuro-Symbolic Heart**
- Implements the **Mediated Reasoning Loop** architecture (LLM as intuitive proposer, UKS as logical verifier)
- **Dual confidence scoring** prevents hallucinations through hybrid validation
- **Knowledge grounding** through entity linking and disambiguation
- **Dynamic learning** through candidate belief systems

---

## 🚀 **Our Journey: The LLM Integration Roadmap**

<div align="center">

| Phase | Status | Focus Area | Key Capabilities |
|-------|---------|------------|------------------|
| **🎯 Phase 1** | ✅ **Completed** | Foundational Bridge | Python-LLM integration, Context management, Knowledge processing |
| **⚡ Phase 2** | 🔄 **In Progress** | Enhanced Reasoning | Collaborative reasoning, Adaptive learning, Confidence validation |
| **🤖 Phase 3** | 📋 **Planned** | True Embodiment | Digital avatars, Goal-oriented behavior, Self-modification |

</div>

### ✅ **Phase 1: The Foundational Bridge** (Completed)
- [x] **Python-LLM Bridge** with OpenAI/Anthropic integration
- [x] **Context Management System** for UKS knowledge extraction
- [x] **Knowledge Processing Engine** for LLM response integration
- [x] **Query-Response Cycles** with UKS context grounding

### ⚡ **Phase 2: Enhanced Reasoning** (In Progress)
- [ ] **Collaborative Reasoning System** - LLM-UKS cooperative problem solving
- [ ] **Adaptive Learning Capabilities** - Dynamic knowledge acquisition
- [ ] **Confidence Scoring & Validation** - Multi-layer truth verification
- [ ] **Temporal Reasoning** - Time-aware knowledge decay and evolution

### 🤖 **Phase 3: Towards Embodiment** 
- [ ] **Digital Avatar Creation** - Persistent AI personalities with memory
- [ ] **Goal-Oriented Behavior** - Autonomous objective setting and pursuit
- [ ] **Multi-Modal Integration** - Vision, audio, and sensory processing
- [ ] **Self-Modification** - Adaptive architecture and capability expansion

📖 **[Detailed Roadmap →](Documentation/LLM_Integration_Roadmap.md)**

---

## 🎪 **Experience BrainSimY**

<div align="center">

### 🔬 **For Researchers & Philosophers**
*Join us in exploring the nature of consciousness, knowledge, and understanding*

### 👨‍💻 **For Developers** 
*Build the future of AI with our comprehensive development platform*

### 🤝 **For Collaborators**
*Shape the future of embodied artificial intelligence*

</div>

#### 📚 **Quick Start Guides**
- 🚀 **[Getting Started Guide](Documentation/GettingStarted.md)** - Set up your development environment
- 🏗️ **[Code Structure](Documentation/CodeStructure.md)** - Understand the architecture
- 🔧 **[Module System](Documentation/ModuleSystem.md)** - Build custom agents and extensions

#### 🤝 **Ways to Contribute**
- **💻 Code**: Contribute modules, optimize performance, extend UKS capabilities
- **🧠 Knowledge**: Help encode common sense knowledge, validate candidate beliefs  
- **💡 Ideas**: Participate in [Future AI Society](https://futureaisociety.org) discussions about the future of AI

---

## 🧠 **About the UKS: The Foundation of Understanding**

The **Universal Knowledge Store (UKS)** is the cognitive foundation that makes BrainSimY unique. Unlike traditional databases or knowledge graphs, the UKS mimics human-like thinking patterns.

### 🔗 **Core Concepts**

**Things & Relationships**: The UKS uses a graph of nodes called "Things" connected by "Relationships." For example: *Fido is-a dog* creates a single is-a relationship linking "Fido" and "dog" Things.

**Inheritance with Exceptions**: Just like human cognition, the UKS implements inheritance so attributes of "dog" automatically apply to "Fido" - but supports exceptions (a three-legged dog named Tripper overrides the "dogs have 4 legs" rule).

**Conditional Logic**: "Clauses" relate multiple Relationships to handle context-dependent facts like "Fido can play fetch IF the weather is sunny."

### 🌟 **Revolutionary Capabilities**

The UKS enables BrainSimY to achieve what other AI systems cannot:

- 🎨 **Multi-sensory Integration** - Connect sounds, words, and images in meaningful ways
- 🗺️ **Real-time Mental Models** - Maintain dynamic awareness of immediate surroundings  
- 🤔 **Handle Uncertainty** - Process nebulous and conflicting information gracefully
- 📈 **Action Learning** - Store which actions lead to positive outcomes in specific situations
- ⚡ **Real-time Updates** - Handle live robotic and interactive applications
- 🔧 **Modular Expansion** - Incorporate specialized agent modules for any functionality

---

## 🌟 **More Than Code: A New Paradigm**

<div align="center">

*This project is an exploration into the nature of consciousness, knowledge, and understanding.*

**We are inspired by the Future AI Society's mission to create AI with common sense—the ability to set goals, build mental models, and understand physics like a child.**

</div>

With the UKS, BrainSimY is **leapfrogging other AI technologies** which are unable to represent the information needed for the understanding that underpins Common Sense. We're not just building another AI system—**we're creating a new paradigm for embodied artificial intelligence**.

### 🔗 **Connect & Explore**

<div align="center">

[![Future AI Society](https://img.shields.io/badge/🌐-Future%20AI%20Society-purple.svg?style=for-the-badge)](https://futureaisociety.org)
[![Documentation](https://img.shields.io/badge/📚-Documentation-blue.svg?style=for-the-badge)](Documentation/)
[![LLM Prototype](https://img.shields.io/badge/🔬-LLM%20Prototype-green.svg?style=for-the-badge)](LLM_Bridge_Prototype/)

</div>

---

<div align="center">

### 🚀 **Ready to Push the Boundaries of What AI Can Become?**

*Join us in forging the future of embodied artificial intelligence.*

**[Get Started →](Documentation/GettingStarted.md)** | **[Explore the Code →](Documentation/CodeStructure.md)** | **[Join the Community →](https://futureaisociety.org)**

---

<sub>**Licensed under MIT** | **Supported by Future AI Society** | **Building the Future of AI Understanding**</sub>

</div> 

